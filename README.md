# Crisis Management Web Scraper

A web scraper that monitors current events from multiple news sources, ranks them by severity, and displays them on a GitHub Pages website.

## Features

- ğŸ” **Multi-Source Scraping**: Fetches news from RSS feeds and APIs
- ğŸ“Š **Severity Ranking**: Automatically ranks events by crisis level
- ğŸŒ **Live Website**: Displays results on GitHub Pages
- âš¡ **Automated Updates**: GitHub Actions runs scraper automatically
- ğŸ“± **Responsive Design**: Mobile-friendly interface

## Severity Criteria

Events are ranked based on:
1. **Keywords**: disaster, crisis, emergency, fatal, casualties
2. **Geographic Scope**: local, regional, national, global
3. **Impact Level**: affected population, economic impact
4. **Urgency**: breaking news vs. ongoing situations

## Setup

### Prerequisites
- Python 3.9 or higher
- Git

### Installation

1. Clone the repository:
```bash
git clone https://github.com/YOUR_USERNAME/crisis-management-scraper.git
cd crisis-management-scraper
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Configure news sources in `config/sources.json`

4. Run the scraper:
```bash
python scraper/main.py
```

## GitHub Pages Deployment

1. Enable GitHub Pages in repository settings
2. Set source to the `docs/` folder
3. GitHub Actions will automatically update the site

## Configuration

Edit `config/sources.json` to add or remove news sources:

```json
{
  "sources": [
    {
      "name": "Example News",
      "type": "rss",
      "url": "https://example.com/rss",
      "enabled": true
    }
  ]
}
```

Edit `config/severity_rules.json` to customize ranking criteria.

## Project Structure

```
.
â”œâ”€â”€ scraper/              # Python scraping modules
â”‚   â”œâ”€â”€ main.py          # Main scraper script
â”‚   â”œâ”€â”€ fetcher.py       # News fetching logic
â”‚   â””â”€â”€ ranker.py        # Severity ranking algorithm
â”œâ”€â”€ docs/                # GitHub Pages website
â”‚   â”œâ”€â”€ index.html       # Main webpage
â”‚   â”œâ”€â”€ styles.css       # Styling
â”‚   â””â”€â”€ app.js           # Frontend logic
â”œâ”€â”€ config/              # Configuration files
â”‚   â”œâ”€â”€ sources.json     # News sources
â”‚   â””â”€â”€ severity_rules.json  # Ranking criteria
â”œâ”€â”€ data/                # Generated data files
â”‚   â””â”€â”€ events.json      # Latest events data
â””â”€â”€ .github/workflows/   # GitHub Actions
    â””â”€â”€ scrape.yml       # Automated scraping workflow

```

## License

MIT License

## Contributing

Pull requests are welcome! Please ensure code follows PEP 8 standards.
